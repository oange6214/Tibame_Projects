{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"efficientnet-minidataset-v3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YAN9AQhZkGMs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1591225492494,"user_tz":-480,"elapsed":20677,"user":{"displayName":"林柏翰","photoUrl":"","userId":"16614042038278778222"}},"outputId":"8e9236b0-e498-4f38-bf50-d37461bf4d14"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HrywWxAXQ8fK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"status":"ok","timestamp":1591261596904,"user_tz":-480,"elapsed":14171,"user":{"displayName":"林柏翰","photoUrl":"","userId":"16614042038278778222"}},"outputId":"e78bae20-df8c-49a3-d86e-ae9ada7caf5e"},"source":["!nvidia-smi\n","!pip install -U git+https://github.com/qubvel/efficientnet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n","Collecting git+https://github.com/qubvel/efficientnet\n","  Cloning https://github.com/qubvel/efficientnet to /tmp/pip-req-build-umczx1f_\n","  Running command git clone -q https://github.com/qubvel/efficientnet /tmp/pip-req-build-umczx1f_\n","Requirement already satisfied, skipping upgrade: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.1.0) (1.0.8)\n","Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.1.0) (0.16.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.18.4)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\n","Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (2.4.1)\n","Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (3.2.1)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (2.4)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\n","Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (7.0.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.1.0) (1.4.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.12.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\n","Building wheels for collected packages: efficientnet\n","  Building wheel for efficientnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet: filename=efficientnet-1.1.0-cp36-none-any.whl size=18327 sha256=11031b17482288d76f2f5f18f0b7c9028c11d544df2bbc2aff60770639963369\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-96i49k8y/wheels/64/60/2e/30ebaa76ed1626e86bfb0cc0579b737fdb7d9ff8cb9522663a\n","Successfully built efficientnet\n","Installing collected packages: efficientnet\n","Successfully installed efficientnet-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGShmwbzQ35a","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","import tensorflow.keras.callbacks as cb\n","import tensorflow.keras.layers as L\n","import tensorflow.keras as K\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","import efficientnet.tfkeras as efn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm.auto import tqdm\n","from glob import glob\n","import os, zipfile, cv2\n","\n","# tf.keras.backend.set_learning_phase(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1XkmQmoQtzP","colab_type":"text"},"source":["# 載入資料\n","        # Coefficients:   width,depth,res,dropout\n","        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n","        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n","        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n","        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n","        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n","        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n","        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n","        'efficientnet-b7': (2.0, 3.1, 600, 0.5),"]},{"cell_type":"code","metadata":{"id":"82WLjkKyV6_9","colab_type":"code","colab":{}},"source":["IMAGE_SIZE = 300\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 100\n","STEPS = 128\n","NUM_CLASSES = 3\n","DATASET_PATH = '/content/datasets/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGrGBfPztO3j","colab_type":"code","colab":{}},"source":["if not os.path.exists('datasets'):\n","    f = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/datasets-300.zip\")\n","    f.extractall(\"./\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xU2_NeBMRhJ2","colab_type":"code","colab":{}},"source":["net = efn.EfficientNetB5(input_shape= (IMAGE_SIZE, IMAGE_SIZE, 3),\n","                         weights= 'noisy-student',\n","                         include_top= False)\n","\n","for layer in net.layers:\n","    layer.trainable = True\n","\n","x = net.output\n","# BN-Relu\n","x = L.BatchNormalization()(x)\n","x = L.Activation('relu')(x)\n","x = L.GlobalMaxPooling2D()(x)\n","out = L.Dense(NUM_CLASSES, activation='softmax')(x)\n","\n","model = Model(inputs=net.input, outputs=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3YvHgQWTbV_","colab_type":"code","colab":{}},"source":["# model.summary()\n","\n","# plot_model(model, to_file='conv_base.png', show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ecttki9xfOQq","colab_type":"code","colab":{}},"source":["import tensorflow.keras as K\n","\n","model.compile(loss= K.losses.CategoricalCrossentropy(), \n","              optimizer= K.optimizers.Adam(amsgrad=True), \n","              metrics= [K.metrics.CategoricalAccuracy()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PV8uTFvTMpDh","colab_type":"code","colab":{}},"source":["def lrfn(epoch):\n","    LR_START = 0.0001\n","    LR_MAX = 0.00005\n","    LR_MIN = 0.0001\n","    LR_RAMPUP_EPOCHS = 4\n","    LR_SUSTAIN_EPOCHS = 6\n","    LR_EXP_DECAY = .8\n","\n","    if epoch < LR_RAMPUP_EPOCHS:\n","        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n","    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n","        lr = LR_MAX\n","    else:\n","        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n","    return lr\n","    \n","lr_callback = cb.LearningRateScheduler(lrfn, verbose=True)\n","\n","rl_callback = cb.ReduceLROnPlateau(monitor = \"val_loss\", \n","                                   factor = 0.5, \n","                                   patience = 5, \n","                                   min_lr = 1e-6)\n","\n","es_callback = cb.EarlyStopping(patience=15, restore_best_weights=True)\n","\n","mc_callback = cb.ModelCheckpoint(os.path.join('/content/drive/My Drive', 'model_siamese.h5'), \n","                              save_best_only=True, \n","                              save_weights_only=False)\n","\n","# rng = [i for i in range(NUM_EPOCHS)]\n","# y = [lrfn(x) for x in rng]\n","# plt.plot(rng, y)\n","# print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))\n","\n","callbacks = [lr_callback,\n","             rl_callback,\n","             es_callback,\n","             mc_callback,\n","             ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hP6zTyQUbVBB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1591255613812,"user_tz":-480,"elapsed":22403,"user":{"displayName":"林柏翰","photoUrl":"","userId":"16614042038278778222"}},"outputId":"d02f5894-16de-46ff-8dfe-f65d521b1df8"},"source":["trn_dagen = ImageDataGenerator(rescale= 1. / 255,\n","                               rotation_range=40,\n","                               width_shift_range=0.2,\n","                               height_shift_range=0.2,\n","                               shear_range=0.2,\n","                               zoom_range=0.2,\n","                               channel_shift_range=10,\n","                               horizontal_flip=True,\n","                               fill_mode='nearest',\n","                               dtype='float32')\n","\n","trn_gen = trn_dagen.flow_from_directory(DATASET_PATH + 'train',\n","                                        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","                                        batch_size=BATCH_SIZE,\n","                                        class_mode='categorical',\n","                                        shuffle=True)\n","\n","val_eva_dagen = ImageDataGenerator(rescale= 1./ 255,\n","                                   validation_split=0.5,\n","                                   dtype='float32')\n","\n","val_gen = val_eva_dagen.flow_from_directory(DATASET_PATH + 'test',\n","                                            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","                                            batch_size= BATCH_SIZE,\n","                                            class_mode='categorical',\n","                                            shuffle=True,\n","                                            subset='training')\n","                                            \n","eva_gen = val_eva_dagen.flow_from_directory(DATASET_PATH + 'test',\n","                                            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","                                            batch_size= BATCH_SIZE,\n","                                            class_mode='categorical',\n","                                            shuffle=True,\n","                                            subset='validation')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1394 images belonging to 3 classes.\n","Found 176 images belonging to 3 classes.\n","Found 173 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"StVR2GxGMo9e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591200822027,"user_tz":-480,"elapsed":3210446,"user":{"displayName":"Pohan Lin","photoUrl":"","userId":"13521014256613017690"}},"outputId":"8f379179-6d74-4a22-f7b3-2758f0331d6d"},"source":["STEP_SIZE_TRAIN = trn_gen.n // BATCH_SIZE\n","STEP_SIZE_VALID = val_gen.n // BATCH_SIZE\n","\n","history = model.fit(trn_gen,\n","                    steps_per_epoch= STEP_SIZE_TRAIN,\n","                    epochs= NUM_EPOCHS,\n","                    verbose= 1,\n","                    validation_data= val_gen,\n","                    validation_steps= STEP_SIZE_VALID,\n","                    callbacks= callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 1/100\n","87/87 [==============================] - 82s 946ms/step - loss: 1.9573 - categorical_accuracy: 0.4869 - val_loss: 1.2573 - val_categorical_accuracy: 0.5795 - lr: 1.0000e-04\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 8.75e-05.\n","Epoch 2/100\n","87/87 [==============================] - 80s 922ms/step - loss: 1.3503 - categorical_accuracy: 0.6132 - val_loss: 1.1486 - val_categorical_accuracy: 0.6818 - lr: 8.7500e-05\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 7.500000000000001e-05.\n","Epoch 3/100\n","87/87 [==============================] - 80s 914ms/step - loss: 1.0489 - categorical_accuracy: 0.6669 - val_loss: 0.6614 - val_categorical_accuracy: 0.7557 - lr: 7.5000e-05\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 6.25e-05.\n","Epoch 4/100\n","87/87 [==============================] - 80s 919ms/step - loss: 0.9358 - categorical_accuracy: 0.6865 - val_loss: 0.6081 - val_categorical_accuracy: 0.7557 - lr: 6.2500e-05\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 5/100\n","87/87 [==============================] - 73s 836ms/step - loss: 0.8173 - categorical_accuracy: 0.7221 - val_loss: 0.7327 - val_categorical_accuracy: 0.7784 - lr: 5.0000e-05\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 6/100\n","87/87 [==============================] - 80s 914ms/step - loss: 0.7423 - categorical_accuracy: 0.7467 - val_loss: 0.5476 - val_categorical_accuracy: 0.8011 - lr: 5.0000e-05\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 7/100\n","87/87 [==============================] - 80s 917ms/step - loss: 0.6431 - categorical_accuracy: 0.7700 - val_loss: 0.5347 - val_categorical_accuracy: 0.8239 - lr: 5.0000e-05\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 8/100\n","87/87 [==============================] - 80s 923ms/step - loss: 0.6171 - categorical_accuracy: 0.7743 - val_loss: 0.5038 - val_categorical_accuracy: 0.8352 - lr: 5.0000e-05\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 9/100\n","87/87 [==============================] - 79s 911ms/step - loss: 0.5576 - categorical_accuracy: 0.7896 - val_loss: 0.4620 - val_categorical_accuracy: 0.8295 - lr: 5.0000e-05\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 10/100\n","87/87 [==============================] - 72s 833ms/step - loss: 0.5820 - categorical_accuracy: 0.7903 - val_loss: 0.5781 - val_categorical_accuracy: 0.8011 - lr: 5.0000e-05\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 5e-05.\n","Epoch 11/100\n","87/87 [==============================] - 79s 906ms/step - loss: 0.5293 - categorical_accuracy: 0.8149 - val_loss: 0.4601 - val_categorical_accuracy: 0.8409 - lr: 5.0000e-05\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 6e-05.\n","Epoch 12/100\n","87/87 [==============================] - 80s 915ms/step - loss: 0.5352 - categorical_accuracy: 0.7990 - val_loss: 0.4373 - val_categorical_accuracy: 0.8466 - lr: 6.0000e-05\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 6.8e-05.\n","Epoch 13/100\n","87/87 [==============================] - 72s 830ms/step - loss: 0.5086 - categorical_accuracy: 0.8019 - val_loss: 0.4818 - val_categorical_accuracy: 0.8466 - lr: 6.8000e-05\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 7.439999999999999e-05.\n","Epoch 14/100\n","87/87 [==============================] - 72s 828ms/step - loss: 0.5739 - categorical_accuracy: 0.7961 - val_loss: 0.5061 - val_categorical_accuracy: 0.8352 - lr: 7.4400e-05\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 7.952e-05.\n","Epoch 15/100\n","87/87 [==============================] - 72s 826ms/step - loss: 0.4930 - categorical_accuracy: 0.8222 - val_loss: 0.4760 - val_categorical_accuracy: 0.8580 - lr: 7.9520e-05\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 8.361600000000001e-05.\n","Epoch 16/100\n","87/87 [==============================] - 79s 909ms/step - loss: 0.4964 - categorical_accuracy: 0.8273 - val_loss: 0.4303 - val_categorical_accuracy: 0.8750 - lr: 8.3616e-05\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 8.68928e-05.\n","Epoch 17/100\n","87/87 [==============================] - 72s 833ms/step - loss: 0.4665 - categorical_accuracy: 0.8266 - val_loss: 0.8510 - val_categorical_accuracy: 0.8295 - lr: 8.6893e-05\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 8.951424e-05.\n","Epoch 18/100\n","87/87 [==============================] - 78s 899ms/step - loss: 0.3358 - categorical_accuracy: 0.8665 - val_loss: 0.3338 - val_categorical_accuracy: 0.8864 - lr: 8.9514e-05\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 9.161139199999999e-05.\n","Epoch 19/100\n","87/87 [==============================] - 72s 829ms/step - loss: 0.3738 - categorical_accuracy: 0.8628 - val_loss: 0.3489 - val_categorical_accuracy: 0.9034 - lr: 9.1611e-05\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 9.32891136e-05.\n","Epoch 20/100\n","87/87 [==============================] - 78s 901ms/step - loss: 0.3906 - categorical_accuracy: 0.8694 - val_loss: 0.3050 - val_categorical_accuracy: 0.8920 - lr: 9.3289e-05\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 9.463129088e-05.\n","Epoch 21/100\n","29/87 [=========>....................] - ETA: 45s - loss: 0.3995 - categorical_accuracy: 0.8599"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n8g8j9zo-XPB","colab_type":"text"},"source":["# 評估模型"]},{"cell_type":"code","metadata":{"id":"dBC9Gsl_9ffl","colab_type":"code","colab":{}},"source":["loss, acc = model.evaluate(eva_gen, steps= len(eva_gen))\n","print('評估的準確率::  ', acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTXiWhvGQWZ2","colab_type":"code","colab":{}},"source":["plt.plot(history.history['categorical_accuracy'])\n","plt.plot(history.history['val_categorical_accuracy'])\n","plt.legend(['acc', 'val_acc'])\n","plt.title('acc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2CIwc3FQazm","colab_type":"code","colab":{}},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.legend(['loss', 'val_loss'])\n","plt.title('loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cHQ5T1sjPnh6","colab_type":"text"},"source":["## 混淆矩陣觀察預測結果"]},{"cell_type":"code","metadata":{"id":"7sjWEiisOYno","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","\n","train, label = eva_gen.next()\n","\n","pre = model.predict(train, steps= 1)\n","pre = pre.argmax(axis= -1)\n","label = label.argmax(axis= -1)\n","\n","df = pd.DataFrame(confusion_matrix(label, pre))\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPpGRaufB116","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}