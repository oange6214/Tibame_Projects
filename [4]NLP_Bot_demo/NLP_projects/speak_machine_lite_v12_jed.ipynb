{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安裝套件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 語音辨識\n",
    "pip install SpeechRecognition\n",
    "## 麥克風錄音\n",
    "pip install pyaudio\n",
    "### Linux 安裝步驟\n",
    "1. First we need to install portaudio modules : sudo apt-get install libasound-dev note:Y\n",
    "\n",
    "2. sudo apt-get install libportaudio-dev note:Y\n",
    "\n",
    "3. Download the portaudio archive from : http://portaudio.com/download.html\n",
    "\n",
    "4. Unzip the archive : tar -zxvf [portaudio.tgz]\n",
    "\n",
    "5. Enter the directory, then run : ./configure && make\n",
    "\n",
    "6. Install : sudo make install\n",
    "\n",
    "7. And finally : sudo pip install pyaudio\n",
    "\n",
    "8. Check the version of pyaudio, it should be 0.2.9\n",
    "\n",
    "9. apt-get install flac\n",
    "\n",
    "## 結巴斷詞\n",
    "pip install jieba\n",
    "## 文字轉語音\n",
    "pip install gTTS\n",
    "## 音檔播放\n",
    "pip install pygame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匯入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk             # Tkinter GUI 主套件\n",
    "import tkinter.ttk as ttk        # Tkinter Style\n",
    "import tempfile                  # 產生暫存檔案\n",
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "\n",
    "from nlp import *\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw ,ImageTk\n",
    "import speech_recognition\n",
    "from datetime import datetime\n",
    "\n",
    "from threading import Timer\n",
    "import threading\n",
    "from queue import Queue\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匯入nlp套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def openCap(SAYHI, debug):\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read('trainer/trainer.yml')\n",
    "    cascadePath = \"Cascades/haarcascade_frontalface_default.xml\"\n",
    "    faceCascade = cv2.CascadeClassifier(cascadePath)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Show FPS\n",
    "    FPS = False\n",
    "\n",
    "    #iniciate id counter\n",
    "    id = 0\n",
    "\n",
    "    # names related to ids: example ==> Marcelo: id=1,  etc\n",
    "    names = ['None', 'Marcelo', 'Paula', 'Ilza', 'Z', 'W']\n",
    "\n",
    "    # Initialize and start realtime video capture\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)  # set video widht\n",
    "    cam.set(4, 480)  # set video height\n",
    "\n",
    "    # Define min window size to be recognized as a face\n",
    "    minW = 0.1 * cam.get(3)\n",
    "    minH = 0.1 * cam.get(4)\n",
    "    \n",
    "    catch = 30\n",
    "    \n",
    "    while SAYHI:\n",
    "        if FPS:\n",
    "            start = time.time() # Start time\n",
    "\n",
    "        ret, img = cam.read()\n",
    "        img = cv2.flip(img, 1)  # Flip vertically\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(int(minW), int(minH))\n",
    "        )\n",
    "        \n",
    "        if debug:\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                id, confidence = recognizer.predict(gray[y:y + h, x:x + w])\n",
    "                \n",
    "                # Check if confidence is less them 100 ==> \"0\" is perfect match\n",
    "                if (confidence < 100):\n",
    "                    id = names[id]\n",
    "                    confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "                    catch -= 1\n",
    "                else:\n",
    "                    id = \"unknown\"\n",
    "                    catch -= 1\n",
    "                    confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "                    \n",
    "                \n",
    "                cv2.putText(img, str(id), (x + 5, y - 5), font, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(img, str(confidence), (x + 5, y + h - 5), font, 1, (255, 255, 0), 2)\n",
    "                \n",
    "            if FPS:\n",
    "                end = time.time()\n",
    "                seconds = end - start\n",
    "                fps = int(1 / seconds)\n",
    "                cv2.putText(img, str(fps), (25, 25), font, 1, (0, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow('camera', img)\n",
    "            \n",
    "        if catch == 0:\n",
    "            break\n",
    "            \n",
    "        k = cv2.waitKey(10) & 0xff  # Press 'ESC' for exiting video\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "    # Do a bit of cleanup\n",
    "    print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立詞向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 讀取 資料集\n",
    "dim, word_vecs = load_WordVector()\n",
    "word_feature = set_word_vector(word_vecs, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義Backstage_Answer_lits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_backstage_answer_list():\n",
    "    answer_list = []\n",
    "    with open('04_Answer_create/backstage_ans.txt', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line.strip().split()\n",
    "            line = tokenize(line)\n",
    "            lines = ''\n",
    "            for i in line:\n",
    "                lines += i\n",
    "\n",
    "            answer_list.append(lines)\n",
    "    return answer_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義Display_answer_lits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_answer_list():\n",
    "    answer_list = {}\n",
    "    lebel = 0\n",
    "    with open('04_Answer_create/display_ans.txt', 'r', encoding='utf-8') as f:\n",
    "        for All_file in f:\n",
    "            Sort_text = All_file.split()\n",
    "            line = tokenize(Sort_text[0])\n",
    "            lines = ''\n",
    "            for i in line:\n",
    "                lines += i\n",
    "            answer_list[lebel] = [lines]\n",
    "\n",
    "            lebel += 1\n",
    "            \n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義問題與答案間向量的計算模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義語音撥放的function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete = True) as fp:\n",
    "        tts = gTTS(text=sentence, lang=\"zh-tw\")\n",
    "        tts.save('{}.mp3'.format(fp.name))\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 關閉視窗function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 錄音按鈕停止動作function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得音訊function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 錄音function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得QRcode.jpg function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入QRcode image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設置顯示Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Display_img(ttk.Frame):\n",
    "    def __init__(self, master=None, qrcode_list=None):\n",
    "        ttk.Frame.__init__(self, master)\n",
    "        self.img_num = 10\n",
    "        self.panel = tk.Label(master, image = qrcode_list[ self.img_num ], bg = 'white' )\n",
    "        self.panel.pack( fill = tk.BOTH ,expan = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backstage_Answer_list = get_backstage_answer_list()\n",
    "Display_Answer_list = get_display_answer_list()\n",
    "mixer.init() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立Tkinter視窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def windowTkinter():\n",
    "    \n",
    "    def save_data(dialogue , ansspeak):\n",
    "        with open(\"data.txt\",\"a\",encoding=\"utf8\") as f: \n",
    "            f.write(\"Q: \" + dialogue +\"  \" + \"A: \" + ansspeak + \"\\n\")\n",
    "        \n",
    "    def predict(question, backstage_answer_list, display_answer_list, debug=False):\n",
    "        # 向量化\n",
    "        avg_dlg_emb = word_feature(question)\n",
    "\n",
    "        if (debug):\n",
    "            print('==='*30)\n",
    "            print(clean_text(question))\n",
    "            print()\n",
    "\n",
    "        max_idx = len(display_answer_list)-1\n",
    "        max_sim = -10\n",
    "        # 在六個回答中，每個答句都取詞向量平均作為向量表示\n",
    "        # 我們選出與 dialogue 句子向量表示 cosine similarity 最高的短句\n",
    "\n",
    "        for idx, ans in enumerate(backstage_answer_list):\n",
    "            print('ans:', ans)\n",
    "            print()\n",
    "            avg_ans_emb = word_feature(ans)\n",
    "\n",
    "\n",
    "            sim = cosine_similarity(avg_dlg_emb, avg_ans_emb) \n",
    "            # clean_text(ans)\n",
    "            if (debug):\n",
    "                print(\"Ans #%d:%s:\" %  (idx, clean_text(ans)))\n",
    "                print(\"Similarity #%d: %f\" % (idx, sim))\n",
    "                print()\n",
    "            if sim > max_sim:\n",
    "                max_idx = idx\n",
    "                max_sim = sim\n",
    "\n",
    "        #更換圖片\n",
    "        display_fram.img_num = max_idx\n",
    "        load_image(qrcode_list[display_fram.img_num])\n",
    "\n",
    "        if max_idx == 13:\n",
    "            now_time = get_time()\n",
    "            display_answer_list[max_idx][0] = now_time\n",
    "\n",
    "    #     for idx, ans in enumerate(answers):\n",
    "    #         print(\"idx: {}\".format(Answer_listR[idx]))\n",
    "    #         print(\"prob: {} \".format(sim))\n",
    "    #         print()\n",
    "    #         print(\"Answer(%d:prob=%f):%s\" % (max_idx, max_sim, answers[max_idx]))\n",
    "\n",
    "        return display_answer_list[max_idx][0] , max_idx\n",
    "    \n",
    "    \n",
    "    def Get_Audio():\n",
    "        # 進行錄音\n",
    "        r = speech_recognition.Recognizer()\n",
    "\n",
    "        with speech_recognition.Microphone() as source:\n",
    "            r.adjust_for_ambient_noise(source, duration=0.5) \n",
    "            audio = r.listen(source)\n",
    "        try:\n",
    "            dialogue = r.recognize_google(audio, language=\"zh-TW\") # 透過 語音辨識 將 錄音資料 轉為 文字\n",
    "            dialogue = dialogue.lower()\n",
    "\n",
    "            listbox.insert(tk.END,\"你說=>\" + dialogue)\n",
    "            listbox.see(tk.END) # 指定 Listbox 看最後一行\n",
    "\n",
    "            dialogue = clean_text(dialogue) # 將問題進行前處理\n",
    "            dialogue=\"\".join(dialogue) # 將 List 轉成字串\n",
    "\n",
    "            pre, max_idx = predict(dialogue, Backstage_Answer_list, Display_Answer_list, True) # 取 答案 和 index\n",
    "            listbox.insert(tk.END,\"我說=> ANS: \" + str(max_idx)+\" \"+pre)\n",
    "            ansspeak = str(max_idx)+\" \"+pre\n",
    "            save_data(dialogue , ansspeak)\n",
    "            listbox.see(tk.END)\n",
    "            speak(pre) # 聲音播放\n",
    "\n",
    "        # 錯誤處理\n",
    "        except speech_recognition.UnknownValueError:\n",
    "            # google 聽不懂\n",
    "            listbox.insert(tk.END,\"Google Speech Recognition could not understand audio\")\n",
    "            listbox.see(tk.END)\n",
    "        except speech_recognition.RequestError as e:\n",
    "            # google 沒有給予回應\n",
    "            listbox.insert(tk.END,\"No response from Google Speech Recognition service: {0}\".format(e))\n",
    "            listbox.see(tk.END)\n",
    "\n",
    "        listbox.see(tk.END)\n",
    "        button_recording_stop()\n",
    "\n",
    "    def recording():\n",
    "        button_recording.config(state=tk.DISABLED) # 停用錄音按鈕\n",
    "        listbox.insert(tk.END, \"您好，請問有甚麼需要服務嗎?\")\n",
    "        listbox.see(tk.END)\n",
    "\n",
    "        speak(\"您好，請問有甚麼需要服務嗎?\")\n",
    "\n",
    "        T_Get_Audio = Timer(3.0,Get_Audio) # 將 CPU 分支出來處理 Get_Audio function 且延遲 3 秒執行\n",
    "        T_Get_Audio.start() # 開始執行 T_Get_Audio function\n",
    "    \n",
    "    def get_image():\n",
    "        image_list=glob.glob('./QRcode/*.jpg',recursive=True) #for recurisve \n",
    "        qrcode = []\n",
    "        for f in image_list:\n",
    "            img = Image.open(f)\n",
    "            img = img.resize((200, 200), Image.ANTIALIAS) ## The (250, 250) is (height, width)\n",
    "            img = ImageTk.PhotoImage(img)\n",
    "            qrcode.append(img)\n",
    "        print(image_list)\n",
    "        return qrcode\n",
    "\n",
    "        # 錄音按鈕 恢復正常\n",
    "    def button_recording_stop():\n",
    "        button_recording.config(state=tk.NORMAL)\n",
    "    \n",
    "    def load_image(img):\n",
    "        display_fram.panel.configure(image=img)\n",
    "    \n",
    "    def Close_Window():\n",
    "        window.destroy()\n",
    "    \n",
    "    # 抓時間\n",
    "    def get_time():\n",
    "        now_time=\"現在時間是 \"+datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        return now_time\n",
    "    \n",
    "    # 建立視窗\n",
    "    window = tk.Tk()\n",
    "    # 設定全螢幕\n",
    "    window.configure(bg='#00ff00')\n",
    "    window.attributes(\"-fullscreen\", True)\n",
    "    # 對話框\n",
    "    listbox = tk.Listbox(window, font=('microsoft yahei', 18), width=70)\n",
    "    # bar\n",
    "    scrollbar = tk.Scrollbar(window)\n",
    "    listbox['yscrollcommand'] = scrollbar.set  # 指定 listbox 的 yscrollbar 回傳函數為 Scrollbar\n",
    "    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    listbox.pack(anchor=tk.NE, side=tk.RIGHT, fill=tk.BOTH)\n",
    "    scrollbar['command'] = listbox.yview  # 指定 scrollbar command 回傳函數為 listbox 的 yview\n",
    "    # 設定圖片檔變數\n",
    "    voice_icon = tk.PhotoImage(file=\"01_GUI/voiceover_1.gif\")\n",
    "    # 錄音按鈕\n",
    "    button_recording = tk.Button(window,\n",
    "                                 image=voice_icon,\n",
    "                                 command=recording,\n",
    "                                 bg='white')\n",
    "    \n",
    "    # image 設定要替代按鈕圖片，command 按下按鈕時要執行的動作\n",
    "    button_recording.pack(side=tk.TOP, fill=tk.BOTH, expan=True)\n",
    "    #取得QRcode\n",
    "    qrcode_list = get_image()\n",
    "    #建立fram以切換qrcode\n",
    "    display_fram = Display_img(master=window, qrcode_list=qrcode_list)\n",
    "    # 關閉視窗安紐\n",
    "    button_close = ttk.Button(window,\n",
    "                              text=\"離開\",\n",
    "                              style=\"TButton\",\n",
    "                              command=Close_Window)\n",
    "    \n",
    "    button_close.pack(side=tk.BOTTOM, fill=tk.BOTH, expan=True)\n",
    "    \n",
    "    ttk.Style().configure(\"TButton\",\n",
    "                          padding=16,\n",
    "                          relief=\"flat\",\n",
    "                          font=('microsoft yahei', 48, \"bold\"))\n",
    "    \n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rootwindow():\n",
    "    \n",
    "    def openCap():\n",
    "        \n",
    "        recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        recognizer.read('trainer/trainer.yml')\n",
    "        cascadePath = \"Cascades/haarcascade_frontalface_default.xml\"\n",
    "        faceCascade = cv2.CascadeClassifier(cascadePath)\n",
    "    #     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        cam.set(3, 640)  # set video widht\n",
    "        cam.set(4, 480)  # set video height\n",
    "    #     Define min window size to be recognized as a face\n",
    "        minW = 0.1 * cam.get(3)\n",
    "        minH = 0.1 * cam.get(4)\n",
    "    #     catch = 30\n",
    "\n",
    "        def stream():\n",
    "    #         nonlocal catch\n",
    "            global catch\n",
    "\n",
    "            ret, img = cam.read()\n",
    "            img = cv2.flip(img, 1)  # Flip vertically\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.2,\n",
    "                minNeighbors=5,\n",
    "                minSize=(int(minW), int(minH))\n",
    "            )\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(gray, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # Check if confidence is less them 100 ==> \"0\" is perfect match\n",
    "                catch -= 1\n",
    "    # #                 print(catch)\n",
    "    #         current_image = Image.fromarray(gray) #将图像转换成Image对象\n",
    "    #         imgtk = ImageTk.PhotoImage(image=current_image)\n",
    "    #         panel.imgtk = imgtk\n",
    "    #         panel.config(image=imgtk)\n",
    "            if catch <= 0:\n",
    "                cam.release()\n",
    "#                 cv2.destroyAllWindows()\n",
    "                root.destroy()\n",
    "\n",
    "            root.after(1, stream)\n",
    "\n",
    "        stream()\n",
    "#           cv2.imshow('camera', img)\n",
    "     \n",
    "#         if catch <= 0:\n",
    "#             break\n",
    "#         k = cv2.waitKey(10) & 0xff  # Press 'ESC' for exiting video\n",
    "#         if k == 27:\n",
    "#             break\n",
    "    # Do a bit of cleanup\n",
    "    \n",
    "#     print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "#     cam.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "   \n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.configure(bg='#000000')\n",
    "    root.attributes(\"-fullscreen\", True)\n",
    "    panel = tk.Label(root)  # initialize image panel\n",
    "    panel.place(x=10000, y=10000)      \n",
    "\n",
    "    openCap()\n",
    "    # root.after(100, openCap)\n",
    "    # video_loop()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./QRcode\\\\qrcode_a.jpg', './QRcode\\\\qrcode_b.jpg', './QRcode\\\\qrcode_c.jpg', './QRcode\\\\qrcode_d.jpg', './QRcode\\\\qrcode_e.jpg', './QRcode\\\\qrcode_f.jpg', './QRcode\\\\qrcode_g.jpg', './QRcode\\\\qrcode_h.jpg', './QRcode\\\\qrcode_i.jpg', './QRcode\\\\qrcode_j.jpg', './QRcode\\\\qrcode_k.jpg', './QRcode\\\\qrcode_l.jpg', './QRcode\\\\qrcode_m.jpg', './QRcode\\\\qrcode_n.jpg', './QRcode\\\\qrcode_o.jpg', './QRcode\\\\qrcode_p.jpg', './QRcode\\\\qrcode_q.jpg', './QRcode\\\\qrcode_r.jpg', './QRcode\\\\qrcode_s.jpg', './QRcode\\\\qrcode_t.jpg', './QRcode\\\\qrcode_u.jpg']\n"
     ]
    }
   ],
   "source": [
    "# # SAYHI = True\n",
    "# while True: \n",
    "# #     openCap(SAYHI, True)\n",
    "#     catch = 30\n",
    "#     rootwindow()\n",
    "windowTkinter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
